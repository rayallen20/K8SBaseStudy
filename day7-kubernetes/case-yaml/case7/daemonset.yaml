apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd-elasticsearch
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
spec:
  selector:
    matchLabels:
      name: fluentd-elasticsearch
  template:
    metadata:
      labels:
        name: fluentd-elasticsearch
    spec:
      tolerations:
      # this toleration is to have the daemonset runnable on master nodes
      # remove it if your masters can't run pods
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      containers:
      - name: fluentd-elasticsearch
        image: harbor.k8s.com/baseimages/fluentd:v2.5.2
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      # 系统日志
      - name: varlog
        hostPath:
          # 要收集宿主机的日志 但日志收集服务是通过pod起来的 所以现在面临的问题是pod要拿到宿主机的日志
          # 1. 日志标准化 所有服务的日志要存放到统一的位置 例如: /data/log/nginx /data/log/kafka /data/log/mysql等
          # 2. 写简单正则 获取所有日志文件 例如: /data/*/*.log
          path: /var/log
      # 容器日志
      - name: varlibdockercontainers
        hostPath:
          # /var/lib/docker/containers 是docker默认存放日志的路径
          path: /var/lib/docker/containers
